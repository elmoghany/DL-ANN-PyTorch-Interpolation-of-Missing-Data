{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elmog\\AppData\\Local\\Temp\\ipykernel_34300\\1847374139.py:15: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import copy\n",
    "\n",
    "#for data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# fetch dataset \n",
    "concrete_compressive_strength = fetch_ucirepo(id=165) \n",
    "\n",
    "# data (as pandas dataframes) \n",
    "X = concrete_compressive_strength.data.features\n",
    "y = concrete_compressive_strength.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features keys:\n",
      "Index(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
      "       'Coarse Aggregate', 'Fine Aggregate', 'Age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f'features keys:\\n{X.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
      "0      540.0                 0.0      0.0  162.0               2.5   \n",
      "1      540.0                 0.0      0.0  162.0               2.5   \n",
      "2      332.5               142.5      0.0  228.0               0.0   \n",
      "3      332.5               142.5      0.0  228.0               0.0   \n",
      "4      198.6               132.4      0.0  192.0               0.0   \n",
      "...      ...                 ...      ...    ...               ...   \n",
      "1025   276.4               116.0     90.3  179.6               8.9   \n",
      "1026   322.2                 0.0    115.6  196.0              10.4   \n",
      "1027   148.5               139.4    108.6  192.7               6.1   \n",
      "1028   159.1               186.7      0.0  175.6              11.3   \n",
      "1029   260.9               100.5     78.3  200.6               8.6   \n",
      "\n",
      "      Coarse Aggregate  Fine Aggregate  Age  Concrete compressive strength  \n",
      "0               1040.0           676.0   28                          79.99  \n",
      "1               1055.0           676.0   28                          61.89  \n",
      "2                932.0           594.0  270                          40.27  \n",
      "3                932.0           594.0  365                          41.05  \n",
      "4                978.4           825.5  360                          44.30  \n",
      "...                ...             ...  ...                            ...  \n",
      "1025             870.1           768.3   28                          44.28  \n",
      "1026             817.9           813.4   28                          31.18  \n",
      "1027             892.4           780.0   28                          23.70  \n",
      "1028             989.6           788.9   28                          32.77  \n",
      "1029             864.5           761.5   28                          32.40  \n",
      "\n",
      "[1030 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# concatenate X & Y into 1 dataframe\n",
    "data = pd.concat([X, y], axis=1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Normalize z-score the data\n",
    "data = ( data - data.mean() ) / data.std(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataOrig = copy.deepcopy( data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace some elements with NAN - method # 1\n",
    "number2NAN = 10\n",
    "values2NAN = np.random.choice(len(data), size=number2NAN)\n",
    "# data['Superplasticizer'][values2NAN] = np.nan\n",
    "data.loc[values2NAN, 'Superplasticizer'] = np.nan\n",
    "rowsWithValidData = np.where(~data['Superplasticizer'].isna())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace some elements with NAN - method # 2\n",
    "# if 'Superplasticizer' in data.columns:\n",
    "#     # Select 10 random indices from X\n",
    "#     random_indices = data.sample(n=10, random_state=42).index\n",
    "#     print(random_indices)\n",
    "#     data.loc[random_indices, 'Superplasticizer'] = np.nan\n",
    "#     print(data.loc[random_indices])\n",
    "# else:\n",
    "#     print(\"The 'Superplasticizer' column does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert from pandas data to tensor\n",
    "# Step 2: Split the data into Train & Test\n",
    "\n",
    "# Superplasticizer column dropped for TRAIN Dataset\n",
    "cols2keep = data.keys()\n",
    "cols2keep = cols2keep.drop('Superplasticizer')\n",
    "\n",
    "#dataframe TRAIN -> train tensor + split data to train data & train labels\n",
    "train_dataT = torch.tensor( data[cols2keep].values ).float()\n",
    "train_dataT = train_dataT[ rowsWithValidData ]\n",
    "\n",
    "train_labelsT = torch.tensor( data['Superplasticizer'].values ).float()\n",
    "train_labelsT = train_labelsT[ rowsWithValidData, None ]\n",
    "\n",
    "#dataframe TEST -> Test tensor + split data to train data & train labels\n",
    "test_dataT = torch.tensor( data[cols2keep].values ).float()\n",
    "test_dataT = test_dataT[ values2NAN ]\n",
    "\n",
    "test_labelsT = torch.tensor( data['Superplasticizer'].values ).float()\n",
    "test_labelsT = test_labelsT[ values2NAN, None ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data: (1030, 9)\n",
      "Train data   : torch.Size([1020, 8])\n",
      "Train label  : torch.Size([1020, 1])\n",
      "Test  data   : torch.Size([10, 8])\n",
      "Test label   : torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# confirm sizes\n",
    "print(f'original data: {data.shape}')\n",
    "print(f'Train data   : {train_dataT.shape}')\n",
    "print(f'Train label  : {train_labelsT.shape}')\n",
    "print(f'Test  data   : {test_dataT.shape}')\n",
    "print(f'Test label   : {test_labelsT.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_dataT, train_labelsT)\n",
    "test_data  = TensorDataset(test_dataT , test_labelsT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: torch.Size([1020, 8])\n",
      "test data shape: torch.Size([10, 8])\n"
     ]
    }
   ],
   "source": [
    "print(f'train data shape: {train_data.tensors[0].shape}')\n",
    "print(f'test data shape: {test_data.tensors[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Translate into dataloader objects\n",
    "batchsize    = 16\n",
    "train_loader = DataLoader(train_data, batch_size=batchsize, shuffle=True, drop_last=True)\n",
    "test_loader  = DataLoader(test_data,  batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "# check sizes of data batches\n",
    "for X, y in train_loader:\n",
    "    print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Deep Learning Model\n",
    "def createTheNet():\n",
    "    class nnClassNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.input = nn.Linear(8,64)\n",
    "            \n",
    "            # self.bnormHidden1 =  nn.BatchNorm1d(39)\n",
    "            self.hidden1 = nn.Linear(64,64)\n",
    "            \n",
    "            # self.bnormHidden2 =  nn.BatchNorm1d(64)\n",
    "            self.hidden2 = nn.Linear(64,10)\n",
    "            \n",
    "            self.output = nn.Linear(10,1)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            \n",
    "            x = F.leaky_relu( self.input(x) )\n",
    "            \n",
    "            # x = self.bnormHidden1(x)\n",
    "            x = F.leaky_relu( self.hidden1(x) )\n",
    "\n",
    "            # x = self.bnormHidden2(x)\n",
    "            x = F.leaky_relu( self.hidden2(x) )\n",
    "            \n",
    "            x = self.output(x)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "    modelInstance = nnClassNet().to(device)\n",
    "    \n",
    "    lossfun = nn.MSELoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(modelInstance.parameters(), lr=0.01)#, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    return modelInstance, lossfun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnClassNet(\n",
       "  (input): Linear(in_features=8, out_features=64, bias=True)\n",
       "  (hidden1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (hidden2): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (output): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model that is has NO ERRORS!\n",
    "\n",
    "net2, lossfun, optimizer = createTheNet()\n",
    "\n",
    "input = torch.rand(39,8).to(device)\n",
    "net2.eval()\n",
    "net2(input)\n",
    "net2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "def trainTheModel(trainedModel, lossfun, optimizer, epochs=100):\n",
    "    \n",
    "    #number of epochs to train\n",
    "    numepochs = epochs\n",
    "    trainedModel.train()\n",
    "        \n",
    "    #initialize losses & accuracy\n",
    "    losses   = torch.zeros(numepochs)\n",
    "    trainAcc = []\n",
    "    testAcc  = []\n",
    "    \n",
    "    for epochi in range(numepochs):\n",
    "        \n",
    "        #batch loss & accuracy\n",
    "        batchLoss = []\n",
    "        batchAcc  = []\n",
    "        \n",
    "        #loop over mini-batches\n",
    "        for X,y in train_loader:\n",
    "            \n",
    "            # push data to GPU\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            #Forward pass & loss\n",
    "            yHat = trainedModel(X)\n",
    "            loss = lossfun(yHat, y)\n",
    "            \n",
    "            #backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #loss from this batch\n",
    "            batchLoss.append(loss.item())\n",
    "            \n",
    "            # accuracy from this batch for categorical data\n",
    "            # batchMathces = (torch.abs(yHat - y)).detach().cpu().float().numpy()\n",
    "            # batchAcc.append(( batchMathces < 1))\n",
    "            \n",
    "            #accuracy from this batch -> for BCE sigmoid\n",
    "            accMatches = torch.sigmoid(yHat) > 0.5 ##\n",
    "            accMatchesNumeric = accMatches.float()\n",
    "            batchAcc.append( torch.mean( (accMatchesNumeric == y).float() ).item() )\n",
    "        \n",
    "        #average accuracy across mini-batches\n",
    "        trainAcc.append(100 * np.mean((batchAcc)))\n",
    "        \n",
    "        #average losses across all mini-batches\n",
    "        losses[epochi] = np.mean(batchLoss)\n",
    "        \n",
    "        ################################\n",
    "        # eval mode\n",
    "        # do not use dropout \n",
    "        # do not use batch normalization instead use avg\n",
    "        trainedModel.eval()\n",
    "        #final forward pass for Test Accuracy\n",
    "        X,y = next(iter(test_loader))\n",
    "        \n",
    "        # push data to GPU\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            yHat = trainedModel(X)\n",
    "            \n",
    "        #compute the test accuracy for categorical data\n",
    "        # testMatches = (torch.abs(yHat - y)).detach().cpu().float().numpy()\n",
    "        # testMatchesNumeric = (testMatches < 1)\n",
    "        # testAcc.append(100 * np.mean( testMatchesNumeric ) )\n",
    "\n",
    "        #compute the test accuracy for BCE sigmoid\n",
    "        testMatches = torch.sigmoid(yHat) > 0.5 \n",
    "        testMatchesNumeric = testMatches.float()\n",
    "        testAcc.append(100 * torch.mean( (testMatchesNumeric == y).float() ).item() )\n",
    "    \n",
    "    return trainAcc, testAcc, losses, trainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
