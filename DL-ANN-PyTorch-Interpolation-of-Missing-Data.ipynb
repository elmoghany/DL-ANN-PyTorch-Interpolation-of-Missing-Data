{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elmog\\AppData\\Local\\Temp\\ipykernel_34300\\1847374139.py:15: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import copy\n",
    "\n",
    "#for data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# fetch dataset \n",
    "concrete_compressive_strength = fetch_ucirepo(id=165) \n",
    "\n",
    "# data (as pandas dataframes) \n",
    "X = concrete_compressive_strength.data.features\n",
    "y = concrete_compressive_strength.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features keys:\n",
      "Index(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
      "       'Coarse Aggregate', 'Fine Aggregate', 'Age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(f'features keys:\\n{X.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
      "0      540.0                 0.0      0.0  162.0               2.5   \n",
      "1      540.0                 0.0      0.0  162.0               2.5   \n",
      "2      332.5               142.5      0.0  228.0               0.0   \n",
      "3      332.5               142.5      0.0  228.0               0.0   \n",
      "4      198.6               132.4      0.0  192.0               0.0   \n",
      "...      ...                 ...      ...    ...               ...   \n",
      "1025   276.4               116.0     90.3  179.6               8.9   \n",
      "1026   322.2                 0.0    115.6  196.0              10.4   \n",
      "1027   148.5               139.4    108.6  192.7               6.1   \n",
      "1028   159.1               186.7      0.0  175.6              11.3   \n",
      "1029   260.9               100.5     78.3  200.6               8.6   \n",
      "\n",
      "      Coarse Aggregate  Fine Aggregate  Age  Concrete compressive strength  \n",
      "0               1040.0           676.0   28                          79.99  \n",
      "1               1055.0           676.0   28                          61.89  \n",
      "2                932.0           594.0  270                          40.27  \n",
      "3                932.0           594.0  365                          41.05  \n",
      "4                978.4           825.5  360                          44.30  \n",
      "...                ...             ...  ...                            ...  \n",
      "1025             870.1           768.3   28                          44.28  \n",
      "1026             817.9           813.4   28                          31.18  \n",
      "1027             892.4           780.0   28                          23.70  \n",
      "1028             989.6           788.9   28                          32.77  \n",
      "1029             864.5           761.5   28                          32.40  \n",
      "\n",
      "[1030 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# concatenate X & Y into 1 dataframe\n",
    "data = pd.concat([X, y], axis=1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Normalize z-score the data\n",
    "data = ( data - data.mean() ) / data.std(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataOrig = copy.deepcopy( data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace some elements with NAN - method # 1\n",
    "number2NAN = 10\n",
    "values2NAN = np.random.choice(len(data), size=number2NAN)\n",
    "# data['Superplasticizer'][values2NAN] = np.nan\n",
    "data.loc[values2NAN, 'Superplasticizer'] = np.nan\n",
    "rowsWithValidData = np.where(~data['Superplasticizer'].isna())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace some elements with NAN - method # 2\n",
    "# if 'Superplasticizer' in data.columns:\n",
    "#     # Select 10 random indices from X\n",
    "#     random_indices = data.sample(n=10, random_state=42).index\n",
    "#     print(random_indices)\n",
    "#     data.loc[random_indices, 'Superplasticizer'] = np.nan\n",
    "#     print(data.loc[random_indices])\n",
    "# else:\n",
    "#     print(\"The 'Superplasticizer' column does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert from pandas data to tensor\n",
    "# Step 2: Split the data into Train & Test\n",
    "\n",
    "# Superplasticizer column dropped for TRAIN Dataset\n",
    "cols2keep = data.keys()\n",
    "cols2keep = cols2keep.drop('Superplasticizer')\n",
    "\n",
    "#dataframe TRAIN -> train tensor + split data to train data & train labels\n",
    "train_dataT = torch.tensor( data[cols2keep].values ).float()\n",
    "train_dataT = train_dataT[ rowsWithValidData ]\n",
    "\n",
    "train_labelsT = torch.tensor( data['Superplasticizer'].values ).float()\n",
    "train_labelsT = train_labelsT[ rowsWithValidData, None ]\n",
    "\n",
    "#dataframe TEST -> Test tensor + split data to train data & train labels\n",
    "test_dataT = torch.tensor( data[cols2keep].values ).float()\n",
    "test_dataT = test_dataT[ values2NAN ]\n",
    "\n",
    "test_labelsT = torch.tensor( data['Superplasticizer'].values ).float()\n",
    "test_labelsT = test_labelsT[ values2NAN, None ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data: (1030, 9)\n",
      "Train data   : torch.Size([1020, 8])\n",
      "Train label  : torch.Size([1020, 1])\n",
      "Test  data   : torch.Size([10, 8])\n",
      "Test label   : torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# confirm sizes\n",
    "print(f'original data: {data.shape}')\n",
    "print(f'Train data   : {train_dataT.shape}')\n",
    "print(f'Train label  : {train_labelsT.shape}')\n",
    "print(f'Test  data   : {test_dataT.shape}')\n",
    "print(f'Test label   : {test_labelsT.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_dataT, train_labelsT)\n",
    "test_data  = TensorDataset(test_dataT , test_labelsT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: torch.Size([1020, 8])\n",
      "test data shape: torch.Size([10, 8])\n"
     ]
    }
   ],
   "source": [
    "print(f'train data shape: {train_data.tensors[0].shape}')\n",
    "print(f'test data shape: {test_data.tensors[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Translate into dataloader objects\n",
    "batchsize    = 16\n",
    "train_loader = DataLoader(train_data, batch_size=batchsize, shuffle=True, drop_last=True)\n",
    "test_loader  = DataLoader(test_data,  batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n",
      "torch.Size([16, 8]) torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "# check sizes of data batches\n",
    "for X, y in train_loader:\n",
    "    print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Deep Learning Model\n",
    "def createTheNet():\n",
    "    class nnClassNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.input = nn.Linear(13,64)\n",
    "            \n",
    "            # self.bnormHidden1 =  nn.BatchNorm1d(39)\n",
    "            self.hidden1 = nn.Linear(64,64)\n",
    "            \n",
    "            # self.bnormHidden2 =  nn.BatchNorm1d(64)\n",
    "            self.hidden2 = nn.Linear(64,10)\n",
    "            \n",
    "            self.output = nn.Linear(10,1)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            \n",
    "            x = F.leaky_relu( self.input(x) )\n",
    "            \n",
    "            # x = self.bnormHidden1(x)\n",
    "            x = F.leaky_relu( self.hidden1(x) )\n",
    "\n",
    "            # x = self.bnormHidden2(x)\n",
    "            x = F.leaky_relu( self.hidden2(x) )\n",
    "            \n",
    "            x = self.output(x)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "    interpolationMissingDataModel = nnClassNet().to(device)\n",
    "    \n",
    "    lossfun = nn.MSELoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(interpolationMissingDataModel.parameters(), lr=0.01)#, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    return interpolationMissingDataModel, lossfun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (39x16 and 13x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m39\u001b[39m,\u001b[38;5;241m16\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m net2\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m----> 7\u001b[0m \u001b[43mnet2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m net2\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[74], line 19\u001b[0m, in \u001b[0;36mcreateTheNet.<locals>.nnClassNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu( \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m )\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# x = self.bnormHidden1(x)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden1(x) )\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (39x16 and 13x64)"
     ]
    }
   ],
   "source": [
    "# test the model that is has NO ERRORS!\n",
    "\n",
    "net2, lossfun, optimizer = createTheNet()\n",
    "\n",
    "input = torch.rand(39,13).to(device)\n",
    "net2.eval()\n",
    "net2(input)\n",
    "net2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
